{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbe86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genlm.control import SMC\n",
    "from genlm.control.sampler import DirectTokenSampler, MultiTokenUnitSampler\n",
    "from genlm.control.sampler.unit import BoundaryPredicate, TokenSetBoundary\n",
    "from genlm.control.potential import Potential\n",
    "from genlm.control.potential.built_in import PromptedLLM\n",
    "from genlm.control.constant import EOS\n",
    "\n",
    "class GoodWordsCritic(Potential):\n",
    "    def __init__(self, vocab, good_words):\n",
    "        super().__init__(vocabulary=vocab, eos=EOS)\n",
    "        self.good_words = set(good_words)\n",
    "    \n",
    "    async def prefix(self, context):\n",
    "        if any(word in context for word in self.good_words):\n",
    "            return -0.3\n",
    "        else:\n",
    "            return -0.5\n",
    "    \n",
    "    async def complete(self, context):\n",
    "        return 0\n",
    "\n",
    "\n",
    "async def example_gpt2_units(llm, max_subunits=10):\n",
    "    llm.set_prompt_from_str(\"Once upon a time\")\n",
    "    print(\"Each 'unit' is a complete sentence ending with . ! or ?\\n\")\n",
    "    \n",
    "    subunit_sampler = DirectTokenSampler(llm)\n",
    "    boundary = TokenSetBoundary(set([v for v in llm.vocab if v.endswith(b\"t\")or v == EOS]))\n",
    "    \n",
    "    unit_sampler = MultiTokenUnitSampler(\n",
    "        subunit_sampler=subunit_sampler,\n",
    "        boundary_predicate=boundary,\n",
    "        max_subunits_per_unit=max_subunits,\n",
    "    )\n",
    "\n",
    "    critic = GoodWordsCritic(llm.vocab, [\"hello\", \"world\"])\n",
    "    sequences = await SMC(unit_sampler, critic=critic)(\n",
    "        n_particles=3,\n",
    "        ess_threshold=0.8,\n",
    "        max_tokens=3,\n",
    "        verbosity=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68c7385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task cancelling name='Task-2334' coro=<AsyncTokenByteTrie._background_loop() running at /opt/miniconda3/envs/gen/lib/python3.12/site-packages/genlm/bytes/trie.py:485> wait_for=<Future cancelled>>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task cancelling name='Task-2335' coro=<AsyncTokenByteTrie._background_loop() running at /opt/miniconda3/envs/gen/lib/python3.12/site-packages/genlm/bytes/trie.py:485> wait_for=<Future cancelled>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Example 1: GPT-2 with Multi-Token Unit Sampling\n",
      "================================================================================\n",
      "--- Example 1a: Sentence-Level Units ---\n",
      "\n",
      "Each 'unit' is a complete sentence ending with . ! or ?\n",
      "\n",
      "Particles: [0.00:\t\u001b[0;35m[\u001b[0m\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0m\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0m\u001b[0;35m]\u001b[0m]\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣they',␣b'␣reached',␣b'␣a',␣b'␣campaign',␣b'␣position',␣b'␣in',␣b'␣2018',␣b'␣by',␣b'␣Peter',␣b'␣to'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb',',␣b'␣seven',␣b'␣times',␣b'␣a',␣b'␣day',␣b',',␣b'␣blind',␣b'fold',␣b'ed',␣b'␣men'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣life',␣b'␣is',␣b'␣as',␣b'␣mine',␣b'␣in',␣b'␣Iz',␣b'la',␣b':',␣b'␣clothing',␣b'␣is'\u001b[0;35m]\u001b[0m\n",
      "Particles: [0.00:\t\u001b[0;35m[\u001b[0mb'␣they',␣b'␣reached',␣b'␣a',␣b'␣campaign',␣b'␣position',␣b'␣in',␣b'␣2018',␣b'␣by',␣b'␣Peter',␣b'␣to'\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0mb',',␣b'␣seven',␣b'␣times',␣b'␣a',␣b'␣day',␣b',',␣b'␣blind',␣b'fold',␣b'ed',␣b'␣men'\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0mb'␣life',␣b'␣is',␣b'␣as',␣b'␣mine',␣b'␣in',␣b'␣Iz',␣b'la',␣b':',␣b'␣clothing',␣b'␣is'\u001b[0;35m]\u001b[0m]\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣they',␣b'␣reached',␣b'␣a',␣b'␣campaign',␣b'␣position',␣b'␣in',␣b'␣2018',␣b'␣by',␣b'␣Peter',␣b'␣to'\u001b[0;35m|\u001b[0mb'␣T',␣b'ait'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb',',␣b'␣seven',␣b'␣times',␣b'␣a',␣b'␣day',␣b',',␣b'␣blind',␣b'fold',␣b'ed',␣b'␣men'\u001b[0;35m|\u001b[0mb'␣appeared',␣b'␣in',␣b'␣Constantinople',␣b',',␣b'␣Turkey',␣b'␣and',␣b'␣the',␣b'␣Crimea',␣b'.',␣b'␣And'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣life',␣b'␣is',␣b'␣as',␣b'␣mine',␣b'␣in',␣b'␣Iz',␣b'la',␣b':',␣b'␣clothing',␣b'␣is'\u001b[0;35m|\u001b[0mb'␣cold',␣b'␣linen',␣b'␣cloth',␣b'␣glean',␣b'ed',␣b'␣from',␣b'␣the',␣b'␣She',␣b'-',␣b'Come'\u001b[0;35m]\u001b[0m\n",
      "Particles: [0.00:\t\u001b[0;35m[\u001b[0mb'␣they',␣b'␣reached',␣b'␣a',␣b'␣campaign',␣b'␣position',␣b'␣in',␣b'␣2018',␣b'␣by',␣b'␣Peter',␣b'␣to'\u001b[0;35m|\u001b[0mb'␣T',␣b'ait'\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0mb',',␣b'␣seven',␣b'␣times',␣b'␣a',␣b'␣day',␣b',',␣b'␣blind',␣b'fold',␣b'ed',␣b'␣men'\u001b[0;35m|\u001b[0mb'␣appeared',␣b'␣in',␣b'␣Constantinople',␣b',',␣b'␣Turkey',␣b'␣and',␣b'␣the',␣b'␣Crimea',␣b'.',␣b'␣And'\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0mb'␣life',␣b'␣is',␣b'␣as',␣b'␣mine',␣b'␣in',␣b'␣Iz',␣b'la',␣b':',␣b'␣clothing',␣b'␣is'\u001b[0;35m|\u001b[0mb'␣cold',␣b'␣linen',␣b'␣cloth',␣b'␣glean',␣b'ed',␣b'␣from',␣b'␣the',␣b'␣She',␣b'-',␣b'Come'\u001b[0;35m]\u001b[0m]\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣they',␣b'␣reached',␣b'␣a',␣b'␣campaign',␣b'␣position',␣b'␣in',␣b'␣2018',␣b'␣by',␣b'␣Peter',␣b'␣to'\u001b[0;35m|\u001b[0mb'␣T',␣b'ait'\u001b[0;35m|\u001b[0mb'\\n',␣b'\\n',␣b'England',␣b\"'s\",␣b'␣Cup',␣b'␣and',␣b'␣UK',␣b'␣Championship',␣b'␣seasons',␣b'␣last'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb',',␣b'␣seven',␣b'␣times',␣b'␣a',␣b'␣day',␣b',',␣b'␣blind',␣b'fold',␣b'ed',␣b'␣men'\u001b[0;35m|\u001b[0mb'␣appeared',␣b'␣in',␣b'␣Constantinople',␣b',',␣b'␣Turkey',␣b'␣and',␣b'␣the',␣b'␣Crimea',␣b'.',␣b'␣And'\u001b[0;35m|\u001b[0mb'␣they',␣b'␣said',␣b':',␣b'␣\"',␣b'N',␣b'ay',␣b',',␣b'␣go',␣b'␣and',␣b'␣get'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣life',␣b'␣is',␣b'␣as',␣b'␣mine',␣b'␣in',␣b'␣Iz',␣b'la',␣b':',␣b'␣clothing',␣b'␣is'\u001b[0;35m|\u001b[0mb'␣cold',␣b'␣linen',␣b'␣cloth',␣b'␣glean',␣b'ed',␣b'␣from',␣b'␣the',␣b'␣She',␣b'-',␣b'Come'\u001b[0;35m|\u001b[0mb'␣(',␣b'mal',␣b'aga',␣b'␣and',␣b'␣vampire',␣b'␣witches',␣b')',␣b'␣with',␣b'␣mages',␣b'␣scor'\u001b[0;35m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm = PromptedLLM.from_name(\"gpt2\")\n",
    "\n",
    "await example_gpt2_units(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3f5a3",
   "metadata": {},
   "source": [
    "# Test Byte Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62b79f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Example 1: GPT-2 with Multi-Token Unit Sampling\n",
      "================================================================================\n",
      "--- Example 1a: Sentence-Level Units ---\n",
      "\n",
      "Each 'unit' is a complete sentence ending with . ! or ?\n",
      "\n",
      "Particles: [0.00:\t\u001b[0;35m[\u001b[0m\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0m\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0m\u001b[0;35m]\u001b[0m]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task cancelling name='Task-2336' coro=<AsyncTokenByteTrie._background_loop() running at /opt/miniconda3/envs/gen/lib/python3.12/site-packages/genlm/bytes/trie.py:485> wait_for=<Future cancelled>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣',␣b't'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣',␣b'i',␣b'n',␣b'␣',␣b'N',␣b'o',␣b'r',␣b't'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb',',␣b'␣',␣b'r',␣b'u',␣b'n',␣b'n',␣b'i',␣b'n',␣b'g',␣b'␣',␣b'S',␣b'l',␣b'a',␣b'c',␣b'k',␣b'␣',␣b'w',␣b'a',␣b's',␣b'␣'\u001b[0;35m]\u001b[0m\n",
      "Particles: [0.00:\t\u001b[0;35m[\u001b[0mb'␣',␣b'i',␣b'n',␣b'␣',␣b'N',␣b'o',␣b'r',␣b't'\u001b[0;35m]\u001b[0m, 0.00:\t\u001b[0;35m[\u001b[0mb'␣',␣b't'\u001b[0;35m]\u001b[0m, -0.00:\t\u001b[0;35m[\u001b[0mb',',␣b'␣',␣b'r',␣b'u',␣b'n',␣b'n',␣b'i',␣b'n',␣b'g',␣b'␣',␣b'S',␣b'l',␣b'a',␣b'c',␣b'k',␣b'␣',␣b'w',␣b'a',␣b's',␣b'␣'\u001b[0;35m]\u001b[0m]\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣',␣b't'\u001b[0;35m|\u001b[0mb'h',␣b'e',␣b'r',␣b'e',␣b'␣',␣b'w',␣b'e',␣b'r',␣b'e',␣b'␣',␣b'n',␣b'o',␣b'␣',␣b's',␣b't'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣',␣b'i',␣b'n',␣b'␣',␣b'N',␣b'o',␣b'r',␣b't'\u001b[0;35m|\u001b[0mb'h',␣b'␣',␣b'A',␣b'm',␣b'e',␣b'r',␣b'i',␣b'c',␣b'a',␣b'n',␣b'␣',␣b'b',␣b'a',␣b's',␣b'e',␣b'b',␣b'a',␣b'l',␣b'l',␣b'␣'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb',',␣b'␣',␣b'r',␣b'u',␣b'n',␣b'n',␣b'i',␣b'n',␣b'g',␣b'␣',␣b'S',␣b'l',␣b'a',␣b'c',␣b'k',␣b'␣',␣b'w',␣b'a',␣b's',␣b'␣'\u001b[0;35m|\u001b[0mb'a',␣b'␣',␣b'h',␣b'o',␣b'b',␣b'b',␣b'y',␣b'␣',␣b'f',␣b'o',␣b'r',␣b'␣',␣b'y',␣b'o',␣b'u',␣b'n',␣b'g',␣b'␣',␣b'p',␣b'r'\u001b[0;35m]\u001b[0m\n",
      "Particles: [-0.00:\t\u001b[0;35m[\u001b[0mb'␣',␣b'i',␣b'n',␣b'␣',␣b'N',␣b'o',␣b'r',␣b't'\u001b[0;35m|\u001b[0mb'h',␣b'␣',␣b'A',␣b'm',␣b'e',␣b'r',␣b'i',␣b'c',␣b'a',␣b'n',␣b'␣',␣b'b',␣b'a',␣b's',␣b'e',␣b'b',␣b'a',␣b'l',␣b'l',␣b'␣'\u001b[0;35m]\u001b[0m, -0.00:\t\u001b[0;35m[\u001b[0mb'␣',␣b't'\u001b[0;35m|\u001b[0mb'h',␣b'e',␣b'r',␣b'e',␣b'␣',␣b'w',␣b'e',␣b'r',␣b'e',␣b'␣',␣b'n',␣b'o',␣b'␣',␣b's',␣b't'\u001b[0;35m]\u001b[0m, -0.00:\t\u001b[0;35m[\u001b[0mb',',␣b'␣',␣b'r',␣b'u',␣b'n',␣b'n',␣b'i',␣b'n',␣b'g',␣b'␣',␣b'S',␣b'l',␣b'a',␣b'c',␣b'k',␣b'␣',␣b'w',␣b'a',␣b's',␣b'␣'\u001b[0;35m|\u001b[0mb'a',␣b'␣',␣b'h',␣b'o',␣b'b',␣b'b',␣b'y',␣b'␣',␣b'f',␣b'o',␣b'r',␣b'␣',␣b'y',␣b'o',␣b'u',␣b'n',␣b'g',␣b'␣',␣b'p',␣b'r'\u001b[0;35m]\u001b[0m]\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣',␣b'i',␣b'n',␣b'␣',␣b'N',␣b'o',␣b'r',␣b't'\u001b[0;35m|\u001b[0mb'h',␣b'␣',␣b'A',␣b'm',␣b'e',␣b'r',␣b'i',␣b'c',␣b'a',␣b'n',␣b'␣',␣b'b',␣b'a',␣b's',␣b'e',␣b'b',␣b'a',␣b'l',␣b'l',␣b'␣'\u001b[0;35m|\u001b[0mb'w',␣b'a',␣b's',␣b'␣',␣b't'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb'␣',␣b't'\u001b[0;35m|\u001b[0mb'h',␣b'e',␣b'r',␣b'e',␣b'␣',␣b'w',␣b'e',␣b'r',␣b'e',␣b'␣',␣b'n',␣b'o',␣b'␣',␣b's',␣b't'\u001b[0;35m|\u001b[0mb'e',␣b'p',␣b's',␣b'␣',␣b'f',␣b'o',␣b'r',␣b'␣',␣b'w',␣b'o',␣b'r',␣b'k',␣b'i',␣b'n',␣b'g',␣b'␣',␣b't'\u001b[0;35m]\u001b[0m\n",
      "-0.50:\t\u001b[0;35m[\u001b[0mb',',␣b'␣',␣b'r',␣b'u',␣b'n',␣b'n',␣b'i',␣b'n',␣b'g',␣b'␣',␣b'S',␣b'l',␣b'a',␣b'c',␣b'k',␣b'␣',␣b'w',␣b'a',␣b's',␣b'␣'\u001b[0;35m|\u001b[0mb'a',␣b'␣',␣b'h',␣b'o',␣b'b',␣b'b',␣b'y',␣b'␣',␣b'f',␣b'o',␣b'r',␣b'␣',␣b'y',␣b'o',␣b'u',␣b'n',␣b'g',␣b'␣',␣b'p',␣b'r'\u001b[0;35m|\u001b[0mb'o',␣b'g',␣b'r',␣b'a',␣b'm',␣b'm',␣b'e',␣b'r',␣b's',␣b';',␣b'␣',␣b'Y',␣b'u',␣b'n',␣b'g',␣b'␣',␣b'C',␣b'h',␣b'e',␣b'u'\u001b[0;35m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from genlm.control.potential.built_in.llm import load_model_by_name\n",
    "from genlm.bytes import BeamParams\n",
    "from genlm.control.potential.built_in import ByteLLM\n",
    "\n",
    "def build_bytelm(llm_name):\n",
    "    llm = load_model_by_name(\"gpt2\", backend=\"hf\")\n",
    "    beam_params = BeamParams(\n",
    "        K=5,\n",
    "        prune_threshold=0.0,\n",
    "    )\n",
    "    return ByteLLM(llm, beam_params)\n",
    "\n",
    "byte_llm = build_bytelm(\"gpt2\")\n",
    "await example_gpt2_units(byte_llm, max_subunits=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38a85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
